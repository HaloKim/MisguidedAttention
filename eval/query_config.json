{
  "llms": [
    {
      "name": "llama-3.1-8B",
      "model": "meta-llama/llama-3.1-8b-instruct",
      "temperature": 0.9,
      "top_p": 1,
      "frequency_penalty": 0,
      "presence_penalty": 0,
      "repetition_penalty": 1,
      "top_k": 0
    },
    {
      "name": "hermes-3-llama-3.1-405",
      "model": "nousresearch/hermes-3-llama-3.1-405b",
      "temperature": 1.0,
      "top_p": 1,
      "repetition_penalty": 1
    },
    {
      "name": "claude-3.5-sonnet",
      "model": "anthropic/claude-3.5-sonnet",
      "temperature": 0.9,
      "top_p": 0.9,
      "repetition_penalty": 1
    },
    {
      "name": "gpt-4o-mini",
      "model": "openai/gpt-4o-mini",
      "temperature": 0.7,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "gpt-4o",
      "model": "openai/gpt-4o",
      "temperature": 0.7,
      "top_p": 1.0,
      "repetition_penalty": 1
    },    
    {
      "name": "gemini-flash-1.5-exp",
      "model": "google/gemini-flash-1.5-ex",
      "temperature": 0.7,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "gemini-pro-1.5",
      "model": "google/gemini-pro-1.5",
      "temperature": 1,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "o1-mini-2024-09-12",
      "model": "openai/o1-mini-2024-09-12",
      "max_tokens": 4000,
      "temperature": 1,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "o1-preview",
      "model": "openai/o1-preview",
      "max_tokens": 4000,
      "temperature": 1,
      "top_p": 1.0,
      "repetition_penalty": 1
    },
    {
      "name": "phi-3-medium-128k-instruct",
      "model": "microsoft/phi-3-medium-128k-instruct",
      "temperature": 0.7,
      "top_p": 1,
      "repetition_penalty": 1
    },
    {
      "name": "mistral-7b-instruct",
      "model": "mistralai/mistral-7b-instruct",
      "temperature": 0.88,
      "top_p": 1,
      "repetition_penalty": 1
    },
    {
      "name": "llama-3.1-405b-instruct",
      "model": "meta-llama/llama-3.1-405b-instruct",
      "max_tokens": 2000,
      "temperature": 0.9,
      "top_p": 1.0,
      "repetition_penalty": 1
    }               
  ]
}
